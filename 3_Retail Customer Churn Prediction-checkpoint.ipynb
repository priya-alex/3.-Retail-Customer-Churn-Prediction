{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4df06358-6c8a-46aa-b930-be3629aeffd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ALL CSVs SAVED — ALL customer-level files include CustomerID\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59e4ea107869457ebb82d27b63ab5c1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='segment', options=('All', 'Medium Value', 'High Value', 'Low Value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# FULL INTERACTIVE CHURN DASHBOARD + CSV EXPORTS WITH CUSTOMERID\n",
    "# All CSVs will include CustomerID correctly.\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from ipywidgets import interact, widgets\n",
    "\n",
    "# -----------------------------\n",
    "# 0. FOLDER SETUP\n",
    "# -----------------------------\n",
    "BASE_FOLDER = \"customer_output_powerbi\"\n",
    "DATA_FOLDER = os.path.join(BASE_FOLDER, \"data\")\n",
    "IMAGES_FOLDER = os.path.join(BASE_FOLDER, \"images\")\n",
    "DOC_FOLDER = os.path.join(BASE_FOLDER, \"documentation\")\n",
    "\n",
    "os.makedirs(DATA_FOLDER, exist_ok=True)\n",
    "os.makedirs(IMAGES_FOLDER, exist_ok=True)\n",
    "os.makedirs(DOC_FOLDER, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 1. GENERATE SYNTHETIC CUSTOMER DATA\n",
    "# -----------------------------\n",
    "np.random.seed(42)\n",
    "num_customers = 500\n",
    "today = pd.Timestamp.today()\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"CustomerID\": range(1000, 1000 + num_customers),\n",
    "    \"TotalPurchases\": np.random.poisson(lam=5, size=num_customers),\n",
    "    \"TotalSpent\": np.random.gamma(2, 50, size=num_customers).round(2),\n",
    "    \"LastPurchaseDate\": today - pd.to_timedelta(np.random.randint(1, 365, size=num_customers), unit='d'),\n",
    "    \"Gender\": np.random.choice([\"Male\", \"Female\"], size=num_customers),\n",
    "    \"Region\": np.random.choice([\"North\", \"South\", \"East\", \"West\"], size=num_customers),\n",
    "    \"Age\": np.random.randint(18, 70, size=num_customers),\n",
    "    \"Income\": np.random.normal(40000, 15000, size=num_customers).round(0),\n",
    "    \"NumComplaints_12m\": np.random.poisson(0.2, size=num_customers),\n",
    "    \"NumSupportCalls_12m\": np.random.poisson(0.5, size=num_customers),\n",
    "    \"PctPurchasesWithDiscount\": np.random.beta(2, 5, size=num_customers),\n",
    "    \"LoyaltyTier\": np.random.choice([\"Bronze\", \"Silver\", \"Gold\"], size=num_customers, p=[0.6, 0.3, 0.1]),\n",
    "    \"LoyaltyPoints\": np.random.poisson(100, size=num_customers),\n",
    "    \"JoinDate\": today - pd.to_timedelta(np.random.randint(365, 365 * 5, size=num_customers), unit='d'),\n",
    "})\n",
    "\n",
    "# Feature engineering\n",
    "df[\"Tenure_days\"] = (today - df[\"JoinDate\"]).dt.days\n",
    "df[\"Recency_days\"] = (today - df[\"LastPurchaseDate\"]).dt.days\n",
    "df[\"Frequency_12m\"] = df[\"TotalPurchases\"]\n",
    "df[\"Monetary\"] = df[\"TotalSpent\"].round(2)\n",
    "df[\"AvgOrderValue\"] = (df[\"TotalSpent\"] / df[\"TotalPurchases\"].replace(0, 1)).round(2)\n",
    "df[\"Est_CLV\"] = (df[\"AvgOrderValue\"] * df[\"Frequency_12m\"] * 0.3 * 1.5).round(2)\n",
    "df[\"Churn\"] = np.where(df[\"Recency_days\"] > 90, 1, 0)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. FEATURES & MODEL INPUT\n",
    "# -----------------------------\n",
    "features_to_drop = [\"Churn\", \"CustomerID\", \"JoinDate\", \"LastPurchaseDate\"]\n",
    "X = pd.get_dummies(df.drop(columns=features_to_drop))\n",
    "y = df[\"Churn\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "# -----------------------------\n",
    "# 3. TRAIN-TEST SPLIT\n",
    "# -----------------------------\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_idx, test_idx in sss.split(X_scaled, y):\n",
    "    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "# -----------------------------\n",
    "# 4. MODEL TRAINING\n",
    "# -----------------------------\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=12,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "proba_test = model.predict_proba(X_test)[:, 1]\n",
    "pred_test = (proba_test >= 0.5).astype(int)\n",
    "\n",
    "# -----------------------------\n",
    "# 5. APPLY PREDICTIONS BACK TO FULL DF\n",
    "# -----------------------------\n",
    "dashboard_df = df.copy()\n",
    "dashboard_df[\"Predicted_Churn\"] = 0\n",
    "dashboard_df[\"Probability_Churn\"] = 0.0\n",
    "\n",
    "dashboard_df.loc[test_idx, \"Predicted_Churn\"] = pred_test\n",
    "dashboard_df.loc[test_idx, \"Probability_Churn\"] = proba_test\n",
    "\n",
    "# -----------------------------\n",
    "# 6. SEGMENTATION\n",
    "# -----------------------------\n",
    "rfm = df[[\"Recency_days\", \"Frequency_12m\", \"Monetary\"]]\n",
    "seg_model = AgglomerativeClustering(n_clusters=3)\n",
    "df[\"Segment\"] = seg_model.fit_predict(rfm)\n",
    "\n",
    "# Map segments by value\n",
    "monetary_avg = df.groupby(\"Segment\")[\"Monetary\"].mean().sort_values()\n",
    "segment_mapping = {seg: label for seg, label in zip(monetary_avg.index, [\"Low Value\", \"Medium Value\", \"High Value\"])}\n",
    "\n",
    "df[\"Segment_Label\"] = df[\"Segment\"].map(segment_mapping)\n",
    "dashboard_df[\"Segment_Label\"] = df[\"Segment_Label\"]\n",
    "\n",
    "# -----------------------------\n",
    "# 7. RECOMMENDATION LOGIC\n",
    "# -----------------------------\n",
    "def recommend(row):\n",
    "    if row[\"Predicted_Churn\"] == 1 and row[\"Segment_Label\"] == \"High Value\":\n",
    "        return \"VIP retention: call + coupon\"\n",
    "    if row[\"Predicted_Churn\"] == 1 and row[\"NumComplaints_12m\"] > 0:\n",
    "        return \"Immediate CS follow-up\"\n",
    "    if row[\"Probability_Churn\"] >= 0.9:\n",
    "        return \"Urgent: high-touch outreach\"\n",
    "    if row[\"Predicted_Churn\"] == 1:\n",
    "        return \"Email + discount\"\n",
    "    return \"Monitor\"\n",
    "\n",
    "dashboard_df[\"Recommended_Action\"] = dashboard_df.apply(recommend, axis=1)\n",
    "\n",
    "# -----------------------------\n",
    "# 8. EXPORT CSVs WITH CUSTOMERID\n",
    "# -----------------------------\n",
    "cleaned_path = os.path.join(DATA_FOLDER, \"cleaned_customer_data.csv\")\n",
    "scores_path = os.path.join(DATA_FOLDER, \"customer_churn_scores_segments.csv\")\n",
    "final_pred_path = os.path.join(DATA_FOLDER, \"final_predictions.csv\")\n",
    "rfm_path = os.path.join(DATA_FOLDER, \"rfm_segmentation.csv\")\n",
    "feat_path = os.path.join(DATA_FOLDER, \"feature_importance.csv\")\n",
    "\n",
    "# 1) Cleaned customer table\n",
    "df.to_csv(cleaned_path, index=False)\n",
    "\n",
    "# 2) Churn scores + segments\n",
    "scores_export = dashboard_df[[\n",
    "    \"CustomerID\", \"Recency_days\", \"Frequency_12m\", \"Monetary\",\n",
    "    \"Segment_Label\", \"Churn\", \"Predicted_Churn\", \"Probability_Churn\",\n",
    "    \"Est_CLV\", \"NumComplaints_12m\", \"NumSupportCalls_12m\"\n",
    "]]\n",
    "scores_export.to_csv(scores_path, index=False)\n",
    "\n",
    "# 3) Final predictions\n",
    "final_export = dashboard_df[[\n",
    "    \"CustomerID\", \"Segment_Label\", \"Predicted_Churn\",\n",
    "    \"Probability_Churn\", \"Recommended_Action\", \"Est_CLV\"\n",
    "]]\n",
    "final_export.to_csv(final_pred_path, index=False)\n",
    "\n",
    "# 4) RFM segmentation\n",
    "rfm_export = df[[\n",
    "    \"CustomerID\", \"Recency_days\", \"Frequency_12m\", \"Monetary\",\n",
    "    \"Segment\", \"Segment_Label\"\n",
    "]]\n",
    "rfm_export.to_csv(rfm_path, index=False)\n",
    "\n",
    "# 5) Feature importance (no CustomerID — correct)\n",
    "imp_df = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"importance\": model.feature_importances_\n",
    "}).sort_values(\"importance\", ascending=False)\n",
    "imp_df.to_csv(feat_path, index=False)\n",
    "\n",
    "print(\"✅ ALL CSVs SAVED — ALL customer-level files include CustomerID\")\n",
    "\n",
    "# -----------------------------\n",
    "# 9. INTERACTIVE JUPYTER DASHBOARD\n",
    "# -----------------------------\n",
    "def churn_dashboard(segment, gender, min_prob):\n",
    "    d = dashboard_df.copy()\n",
    "\n",
    "    if segment != \"All\":\n",
    "        d = d[d[\"Segment_Label\"] == segment]\n",
    "    if gender != \"All\":\n",
    "        d = d[d[\"Gender\"] == gender]\n",
    "\n",
    "    d = d[d[\"Probability_Churn\"] >= min_prob]\n",
    "\n",
    "    fig1 = px.bar(\n",
    "        d.groupby(\"Segment_Label\")[\"Predicted_Churn\"].mean().reset_index(),\n",
    "        x=\"Segment_Label\", y=\"Predicted_Churn\",\n",
    "        title=\"Predicted Churn Rate by Segment\"\n",
    "    )\n",
    "    fig1.show()\n",
    "\n",
    "    fig2 = px.histogram(d, x=\"Est_CLV\", nbins=30, title=\"CLV Distribution\")\n",
    "    fig2.show()\n",
    "\n",
    "    display(d[[\n",
    "        \"CustomerID\", \"Segment_Label\", \"Probability_Churn\",\n",
    "        \"Recommended_Action\", \"Est_CLV\"\n",
    "    ]].sort_values(\"Probability_Churn\", ascending=False).head(10))\n",
    "\n",
    "interact(\n",
    "    churn_dashboard,\n",
    "    segment=widgets.Dropdown(options=[\"All\"] + list(df[\"Segment_Label\"].unique())),\n",
    "    gender=widgets.Dropdown(options=[\"All\", \"Male\", \"Female\"]),\n",
    "    min_prob=widgets.FloatSlider(min=0, max=1, step=0.05, value=0)\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe0df65-b855-4afd-8d3c-08979366b04a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
